# Data Directory

Contains data for test purpose.

Files for model train/test are made with two steps: first-tokenization and second-tokenization.
- `pretok` contains first-tokenized files.
    - `*.en` tokenizes with Moses tokenizer.
    - `*.ja` tokenizes with Mecab tokenizer.
- `*.en` and `*.ja` in root directory are tokenized with Sentencepiece after first-tokenization.
- `detok` contains raw texts.

Sentencepiece tokenization is trained separately en/ja.
`*.model` and `*.vocab` is model and vocabulary file generated by Sentencepiece.

`data-bin` contains dictionary and binarized file from `*.en` and `*.ja` by using Fairseq.

`checkpoints` contains pre-trained tiny Transformer model.

For more details, see [here](https://github.com/naist-nlp/toymt)
